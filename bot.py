import os
import uuid
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
import numpy as np

from aiogram import Bot, Dispatcher, Router, F
from aiogram.types import (
    Message, CallbackQuery, InlineKeyboardMarkup,
    InlineKeyboardButton, InputFile, FSInputFile
)
from aiogram.filters import Command, CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.client.default import DefaultBotProperties

# Audio processing libraries
try:
    from pydub import AudioSegment
    from moviepy.editor import AudioFileClip, CompositeAudioClip, concatenate_audioclips
    import numpy as np
    AUDIO_SUPPORT = True
except ImportError:
    AUDIO_SUPPORT = False
    print("Audio processing libraries not installed. Install with: pip install pydub moviepy numpy")

# Bot configuration
BOT_TOKEN = "8387242598:AAHFfLJ5JLnYz5_ENSoM7sn3c7bT7L5pRPk"
ADMIN_USERNAME = "@Daykkaa"

# Initialize bot
bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router()
dp.include_router(router)

# Create directories
UPLOAD_DIR = Path("uploads")
EFFECTS_DIR = Path("effects")
UPLOAD_DIR.mkdir(exist_ok=True)
EFFECTS_DIR.mkdir(exist_ok=True)

# States
class AudioStates(StatesGroup):
    waiting_for_audio = State()
    choosing_effects = State()
    processing_audio = State()

# Audio Effect Definitions
class AudioEffect:
    def __init__(self, name: str, description: str, types: List[str]):
        self.name = name
        self.description = description
        self.types = types
    
    def apply(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply effect to audio"""
        if self.name == "Echo":
            return self._apply_echo(audio, effect_type)
        elif self.name == "Reverb":
            return self._apply_reverb(audio, effect_type)
        elif self.name == "Speed":
            return self._apply_speed(audio, effect_type)
        elif self.name == "Pitch":
            return self._apply_pitch(audio, effect_type)
        elif self.name == "Volume":
            return self._apply_volume(audio, effect_type)
        elif self.name == "Fade":
            return self._apply_fade(audio, effect_type)
        elif self.name == "Reverse":
            return self._apply_reverse(audio, effect_type)
        elif self.name == "Distortion":
            return self._apply_distortion(audio, effect_type)
        elif self.name == "Chorus":
            return self._apply_chorus(audio, effect_type)
        elif self.name == "Flanger":
            return self._apply_flanger(audio, effect_type)
        elif self.name == "Equalizer":
            return self._apply_equalizer(audio, effect_type)
        # Add more effects as needed
        return audio
    
    def _apply_echo(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply echo effect"""
        if effect_type == "Soft Echo":
            # Light echo
            echo = audio - 10
            echo = echo.fade_out(100).fade_in(100)
            return audio.overlay(audio, gain_during_overlay=-6).overlay(echo, gain_during_overlay=-12, position=200)
        elif effect_type == "Medium Echo":
            # Medium echo
            echo = audio - 8
            return audio.overlay(audio, gain_during_overlay=-4).overlay(echo, gain_during_overlay=-10, position=300)
        elif effect_type == "Strong Echo":
            # Strong echo
            echo1 = audio - 6
            echo2 = audio - 12
            result = audio.overlay(audio, gain_during_overlay=-2)
            result = result.overlay(echo1, gain_during_overlay=-8, position=250)
            return result.overlay(echo2, gain_during_overlay=-14, position=500)
        elif effect_type == "Multi Echo":
            # Multiple echoes
            result = audio
            for i in range(1, 4):
                echo = audio - (i * 4)
                result = result.overlay(echo, gain_during_overlay=-8*i, position=150*i)
            return result
        return audio
    
    def _apply_reverb(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply reverb effect (simulated)"""
        if effect_type == "Room Reverb":
            return audio._spawn(audio.raw_data)
        elif effect_type == "Hall Reverb":
            return audio._spawn(audio.raw_data)
        elif effect_type == "Cathedral Reverb":
            return audio._spawn(audio.raw_data)
        elif effect_type == "Plate Reverb":
            return audio._spawn(audio.raw_data)
        return audio
    
    def _apply_speed(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply speed change"""
        speed_factors = {
            "Slow (0.75x)": 0.75,
            "Normal": 1.0,
            "Fast (1.25x)": 1.25,
            "Very Fast (1.5x)": 1.5
        }
        factor = speed_factors.get(effect_type, 1.0)
        
        # Change speed by changing frame rate
        new_frame_rate = int(audio.frame_rate * factor)
        return audio._spawn(audio.raw_data, overrides={'frame_rate': new_frame_rate})
    
    def _apply_pitch(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply pitch shift (simulated with speed change)"""
        pitch_factors = {
            "Low Pitch": 0.8,
            "Normal Pitch": 1.0,
            "High Pitch": 1.2,
            "Very High Pitch": 1.4
        }
        factor = pitch_factors.get(effect_type, 1.0)
        
        # Simple pitch shift via speed change
        new_sample_rate = int(audio.frame_rate * factor)
        shifted = audio._spawn(audio.raw_data, overrides={'frame_rate': new_sample_rate})
        return shifted.set_frame_rate(audio.frame_rate)
    
    def _apply_volume(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply volume change"""
        volume_changes = {
            "Quiet (-10dB)": -10,
            "Normal": 0,
            "Loud (+5dB)": 5,
            "Very Loud (+10dB)": 10
        }
        change = volume_changes.get(effect_type, 0)
        return audio + change
    
    def _apply_fade(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply fade effects"""
        if effect_type == "Fade In":
            return audio.fade_in(1000)
        elif effect_type == "Fade Out":
            return audio.fade_out(1000)
        elif effect_type == "Fade In/Out":
            return audio.fade_in(500).fade_out(500)
        elif effect_type == "Crossfade":
            return audio  # Would need another audio to crossfade with
        return audio
    
    def _apply_reverse(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply reverse effect"""
        return audio.reverse()
    
    def _apply_distortion(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply distortion effect"""
        # Simple distortion by clipping
        samples = np.array(audio.get_array_of_samples())
        
        if effect_type == "Light Distortion":
            threshold = 0.7
        elif effect_type == "Medium Distortion":
            threshold = 0.5
        elif effect_type == "Heavy Distortion":
            threshold = 0.3
        elif effect_type == "Extreme Distortion":
            threshold = 0.1
        else:
            return audio
        
        # Clip samples
        max_val = np.max(np.abs(samples))
        threshold_val = max_val * threshold
        samples = np.clip(samples, -threshold_val, threshold_val)
        
        # Create new audio
        return audio._spawn(samples.tobytes())
    
    def _apply_chorus(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply chorus effect"""
        # Simplified chorus effect
        if effect_type == "Light Chorus":
            delay = 30
        elif effect_type == "Medium Chorus":
            delay = 50
        elif effect_type == "Heavy Chorus":
            delay = 80
        elif effect_type == "Wide Chorus":
            delay = 100
        else:
            return audio
        
        # Create delayed copy
        delayed = AudioSegment.silent(duration=delay) + audio
        return audio.overlay(delayed, gain_during_overlay=-6)
    
    def _apply_flanger(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply flanger effect (simulated)"""
        return audio  # Implementation would be complex
    
    def _apply_equalizer(self, audio: AudioSegment, effect_type: str) -> AudioSegment:
        """Apply equalizer presets"""
        # Simple EQ by adjusting frequencies
        if effect_type == "Bass Boost":
            # Boost low frequencies
            return audio.low_pass_filter(300) + audio - 3
        elif effect_type == "Treble Boost":
            # Boost high frequencies
            return audio.high_pass_filter(3000) + audio - 3
        elif effect_type == "Vocal Boost":
            # Boost mid frequencies for vocals
            return audio - 6  # Simplified
        elif effect_type == "Flat":
            return audio
        return audio

# Define all available effects
EFFECTS = [
    AudioEffect("Echo", "ğŸ”ï¸ JaÅˆ efekti", ["Soft Echo", "Medium Echo", "Strong Echo", "Multi Echo"]),
    AudioEffect("Reverb", "ğŸ›ï¸ Reverb efekti", ["Room Reverb", "Hall Reverb", "Cathedral Reverb", "Plate Reverb"]),
    AudioEffect("Speed", "âš¡ Tizlik Ã¼Ã½tgetmek", ["Slow (0.75x)", "Normal", "Fast (1.25x)", "Very Fast (1.5x)"]),
    AudioEffect("Pitch", "ğŸµ Pitch Ã¼Ã½tgetmek", ["Low Pitch", "Normal Pitch", "High Pitch", "Very High Pitch"]),
    AudioEffect("Volume", "ğŸ”Š Ses gÃ¼Ã½Ã§lendiriji", ["Quiet (-10dB)", "Normal", "Loud (+5dB)", "Very Loud (+10dB)"]),
    AudioEffect("Fade", "ğŸŒŠ Fade efekti", ["Fade In", "Fade Out", "Fade In/Out", "Crossfade"]),
    AudioEffect("Reverse", "ğŸ” Tersine efekti", ["Reverse Audio"]),
    AudioEffect("Distortion", "ğŸ¸ Distortion efekti", ["Light Distortion", "Medium Distortion", "Heavy Distortion", "Extreme Distortion"]),
    AudioEffect("Chorus", "ğŸ¤ Chorus efekti", ["Light Chorus", "Medium Chorus", "Heavy Chorus", "Wide Chorus"]),
    AudioEffect("Flanger", "ğŸŒ€ Flanger efekti", ["Light Flanger", "Medium Flanger", "Heavy Flanger", "Wide Flanger"]),
    AudioEffect("Equalizer", "ğŸ›ï¸ Ekwalizer", ["Bass Boost", "Treble Boost", "Vocal Boost", "Flat"]),
]

# User session data
user_sessions: Dict[int, Dict] = {}

@router.message(CommandStart())
async def cmd_start(message: Message, state: FSMContext):
    """Start command handler"""
    user_id = message.from_user.id
    username = message.from_user.username
    
    welcome_text = f"""
âœ¨ <b>ğŸ§ Audio Effect Bot-a hoÅŸ geldiÅˆiz!</b> âœ¨

ğŸ¤– <b>Bot hakynda:</b>
Bu bot MP3 faÃ½llaryÅˆyza dÃ¼rli audio effektler goÅŸup berÃ½Ã¤r.

ğŸ“Š <b>ElÃ½eterli effektler:</b>
â€¢ ğŸ”ï¸ JaÅˆ (Echo) effekti
â€¢ ğŸ›ï¸ Reverb effekti  
â€¢ âš¡ Tizlik Ã¼Ã½tgetiji
â€¢ ğŸµ Pitch Ã¼Ã½tgetiji
â€¢ ğŸ”Š Ses gÃ¼Ã½Ã§lendiriji
â€¢ ğŸŒŠ Fade effekti
â€¢ ğŸ” Tersine effekti
â€¢ ğŸ¸ Distortion effekti
â€¢ ğŸ¤ Chorus effekti
â€¢ ğŸŒ€ Flanger effekti
â€¢ ğŸ›ï¸ Ekwalizer

ğŸš€ <b>BaÅŸlamak Ã¼Ã§in:</b>
1ï¸âƒ£ MP3 faÃ½lyÅˆyzy Ã½Ã¼klÃ¤Åˆ
2ï¸âƒ£ GoÅŸmak isleÃ½Ã¤n effektleriÅˆizi saÃ½laÅˆ
3ï¸âƒ£ ğŸ”„ "TÃ¤ze effektler goÅŸulan MP3 Ã½Ã¼kle" dÃ¼wmesine basyÅˆ

ğŸ’¡ <b>ÃolbaÅŸÃ§ylyk:</b> Bir gezekde birnÃ¤Ã§e effekt saÃ½lap bilersiÅˆiz!

ğŸ‘¨â€ğŸ’» <b>Admin:</b> {ADMIN_USERNAME}
    """
    
    # Create inline keyboard
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸµ MP3 ÃÃ¼kle", callback_data="upload_audio")],
        [InlineKeyboardButton(text="ğŸ“š Effektleri GÃ¶r", callback_data="show_effects")],
        [InlineKeyboardButton(text="â„¹ï¸ Bot Hakda", callback_data="about_bot")],
        [InlineKeyboardButton(text="ğŸ†˜ KÃ¶mek", callback_data="help")]
    ])
    
    await message.answer(welcome_text, reply_markup=keyboard)
    await state.clear()

@router.callback_query(F.data == "upload_audio")
async def process_upload(callback: CallbackQuery, state: FSMContext):
    """Process audio upload"""
    await callback.answer()
    await callback.message.answer("ğŸµ <b>MP3 faÃ½lyÅˆyzy Ã½Ã¼klÃ¤Åˆ...</b>\n\nğŸ“¤ FaÃ½ly ÅŸu Ã½ere Ã½Ã¼klemegiÅˆizi haÃ½yÅŸ edÃ½Ã¤ris.")
    await state.set_state(AudioStates.waiting_for_audio)

@router.message(AudioStates.waiting_for_audio, F.audio | F.document | F.voice)
async def handle_audio_upload(message: Message, state: FSMContext):
    """Handle uploaded audio file"""
    user_id = message.from_user.id
    
    # Initialize user session
    user_sessions[user_id] = {
        'effects': [],
        'audio_path': None,
        'original_filename': None
    }
    
    try:
        # Get file ID
        if message.audio:
            file_id = message.audio.file_id
            filename = message.audio.file_name or f"audio_{user_id}.mp3"
        elif message.document and message.document.mime_type and 'audio' in message.document.mime_type:
            file_id = message.document.file_id
            filename = message.document.file_name or f"audio_{user_id}.mp3"
        elif message.voice:
            file_id = message.voice.file_id
            filename = f"voice_{user_id}.ogg"
        else:
            await message.answer("âŒ <b>NÃ¤dogry faÃ½l gÃ¶rnÃ¼ÅŸi!</b>\n\nAudio faÃ½ly Ã½Ã¼klemegiÅˆizi haÃ½yÅŸ edÃ½Ã¤ris.")
            return
        
        # Download file
        file = await bot.get_file(file_id)
        file_path = file.file_path
        
        # Generate unique filename
        unique_id = str(uuid.uuid4())[:8]
        save_path = UPLOAD_DIR / f"{user_id}_{unique_id}_{filename}"
        
        # Download file
        await bot.download_file(file_path, save_path)
        
        # Store in session
        user_sessions[user_id]['audio_path'] = str(save_path)
        user_sessions[user_id]['original_filename'] = filename
        
        # Convert to MP3 if needed
        if not str(save_path).lower().endswith('.mp3'):
            try:
                audio = AudioSegment.from_file(save_path)
                mp3_path = save_path.with_suffix('.mp3')
                audio.export(mp3_path, format="mp3")
                save_path.unlink()  # Remove original
                save_path = mp3_path
                user_sessions[user_id]['audio_path'] = str(save_path)
            except Exception as e:
                print(f"Conversion error: {e}")
        
        # Show success message
        success_text = f"""
âœ… <b>Audio faÃ½lyÅˆyz Ã¼stÃ¼nlikli Ã½Ã¼klenildi!</b>

ğŸ“ <b>FaÃ½l ady:</b> {filename}
ğŸ“Š <b>Indi effektleri saÃ½lap bilersiÅˆiz:</b>
        """
        
        # Create effect selection keyboard
        keyboard = await create_effects_keyboard(user_id)
        
        await message.answer(success_text, reply_markup=keyboard)
        await state.set_state(AudioStates.choosing_effects)
        
    except Exception as e:
        print(f"Error handling audio: {e}")
        await message.answer("âŒ <b>FaÃ½ly Ã½Ã¼klÃ¤p bolmady!</b>\n\nGaÃ½tadan synanyÅŸyÅˆ Ã½a-da baÅŸga faÃ½l iÅˆediÅˆ.")

async def create_effects_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """Create keyboard for selecting effects"""
    user_session = user_sessions.get(user_id, {})
    selected_effects = user_session.get('effects', [])
    
    keyboard = []
    
    # Add effects in rows of 2
    for i in range(0, len(EFFECTS), 2):
        row = []
        for effect in EFFECTS[i:i+2]:
            effect_id = f"effect_{EFFECTS.index(effect)}"
            is_selected = effect_id in selected_effects
            
            # Create button with emoji
            emoji = "âœ…" if is_selected else "âšª"
            button_text = f"{emoji} {effect.name}"
            
            row.append(InlineKeyboardButton(
                text=button_text,
                callback_data=f"select_{effect_id}"
            ))
        keyboard.append(row)
    
    # Add effect type selection buttons
    keyboard.append([InlineKeyboardButton(text="ğŸ”§ Her EffektiÅˆ GÃ¶rnÃ¼ÅŸini SaÃ½la", callback_data="select_types")])
    
    # Add action buttons
    action_row = []
    if selected_effects:
        action_row.append(InlineKeyboardButton(text="ğŸ”„ Audio-Ã½ iÅŸle", callback_data="process_audio"))
    
    action_row.append(InlineKeyboardButton(text="ğŸ—‘ï¸ SaÃ½lananlary Arassala", callback_data="clear_selected"))
    keyboard.append(action_row)
    
    # Add back button
    keyboard.append([InlineKeyboardButton(text="â†©ï¸ BaÅŸ Menu", callback_data="back_to_start")])
    
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

@router.callback_query(F.data.startswith("select_effect_"))
async def select_effect(callback: CallbackQuery):
    """Select/deselect an effect"""
    user_id = callback.from_user.id
    
    if user_id not in user_sessions:
        await callback.answer("âŒ Audio faÃ½ly Ã½Ã¼kleÅˆ!", show_alert=True)
        return
    
    # Extract effect index
    effect_idx = int(callback.data.split("_")[2])
    
    if effect_idx >= len(EFFECTS):
        await callback.answer("âŒ NÃ¤dogry effekt!", show_alert=True)
        return
    
    effect_id = f"effect_{effect_idx}"
    
    # Toggle selection
    if effect_id in user_sessions[user_id]['effects']:
        user_sessions[user_id]['effects'].remove(effect_id)
    else:
        user_sessions[user_id]['effects'].append(effect_id)
    
    # Update keyboard
    keyboard = await create_effects_keyboard(user_id)
    
    await callback.message.edit_reply_markup(reply_markup=keyboard)
    await callback.answer()

@router.callback_query(F.data == "select_types")
async def select_effect_types(callback: CallbackQuery):
    """Select specific types for each effect"""
    user_id = callback.from_user.id
    
    if user_id not in user_sessions:
        await callback.answer("âŒ Audio faÃ½ly Ã½Ã¼kleÅˆ!", show_alert=True)
        return
    
    # Create keyboard for effect type selection
    keyboard = []
    selected_effects = user_sessions[user_id]['effects']
    
    for effect_id in selected_effects:
        effect_idx = int(effect_id.split("_")[1])
        effect = EFFECTS[effect_idx]
        
        # Add effect name as button (non-clickable)
        keyboard.append([
            InlineKeyboardButton(
                text=f"ğŸ›ï¸ {effect.name}",
                callback_data="no_action"
            )
        ])
        
        # Add effect type buttons
        type_row = []
        for etype in effect.types:
            type_btn = InlineKeyboardButton(
                text=etype,
                callback_data=f"type_{effect_idx}_{effect.types.index(etype)}"
            )
            type_row.append(type_btn)
            if len(type_row) == 2:  # 2 buttons per row
                keyboard.append(type_row)
                type_row = []
        
        if type_row:  # Add remaining buttons
            keyboard.append(type_row)
        
        # Add separator
        keyboard.append([
            InlineKeyboardButton(text="â”€â”€â”€â”€â”€â”€â”€â”€", callback_data="no_action")
        ])
    
    # Add back button
    keyboard.append([
        InlineKeyboardButton(text="â†©ï¸ Yza", callback_data="back_to_effects"),
        InlineKeyboardButton(text="ğŸš€ IÅŸle", callback_data="process_audio")
    ])
    
    await callback.message.edit_text(
        "ğŸ”§ <b>Her effektiÅˆ gÃ¶rnÃ¼ÅŸini saÃ½laÅˆ:</b>\n\n"
        "AÅŸakdakylardan her effektiÅˆ gÃ¶rnÃ¼ÅŸini saÃ½lap bilersiÅˆiz.",
        reply_markup=InlineKeyboardMarkup(inline_keyboard=keyboard)
    )
    await callback.answer()

@router.callback_query(F.data.startswith("type_"))
async def select_effect_type(callback: CallbackQuery):
    """Select specific type for an effect"""
    user_id = callback.from_user.id
    
    # Parse data
    parts = callback.data.split("_")
    effect_idx = int(parts[1])
    type_idx = int(parts[2])
    
    if effect_idx >= len(EFFECTS):
        await callback.answer("âŒ NÃ¤dogry effekt!", show_alert=True)
        return
    
    effect = EFFECTS[effect_idx]
    
    if type_idx >= len(effect.types):
        await callback.answer("âŒ NÃ¤dogry gÃ¶rnÃ¼ÅŸ!", show_alert=True)
        return
    
    # Store selected type
    effect_id = f"effect_{effect_idx}"
    if 'effect_types' not in user_sessions[user_id]:
        user_sessions[user_id]['effect_types'] = {}
    
    user_sessions[user_id]['effect_types'][effect_id] = effect.types[type_idx]
    
    await callback.answer(f"âœ… {effect.name}: {effect.types[type_idx]} saÃ½landy!")

@router.callback_query(F.data == "process_audio")
async def process_audio(callback: CallbackQuery, state: FSMContext):
    """Process audio with selected effects"""
    user_id = callback.from_user.id
    
    if user_id not in user_sessions or not user_sessions[user_id]['effects']:
        await callback.answer("âŒ Effekt saÃ½lanmady!", show_alert=True)
        return
    
    # Check if audio file exists
    audio_path = user_sessions[user_id].get('audio_path')
    if not audio_path or not Path(audio_path).exists():
        await callback.answer("âŒ Audio faÃ½ly tapylmady!", show_alert=True)
        return
    
    await callback.answer("ğŸ”„ Audio iÅŸlenilÃ½Ã¤r...")
    
    # Show processing message
    processing_msg = await callback.message.answer("""
â³ <b>Audio iÅŸlenilÃ½Ã¤r...</b>

ğŸ”§ <b>SaÃ½lanan effektler:</b>
""" + "\n".join([f"â€¢ {EFFECTS[int(eid.split('_')[1])].name}" 
                for eid in user_sessions[user_id]['effects']]) + """

â° <b>Bu birnÃ¤Ã§e minut wagt alyp biler...</b>
""")
    
    try:
        # Load audio file
        audio = AudioSegment.from_file(audio_path)
        
        # Apply selected effects
        for effect_id in user_sessions[user_id]['effects']:
            effect_idx = int(effect_id.split('_')[1])
            effect = EFFECTS[effect_idx]
            
            # Get selected type or use default
            effect_type = user_sessions[user_id].get('effect_types', {}).get(
                effect_id, effect.types[0] if effect.types else "Default"
            )
            
            # Apply effect
            audio = effect.apply(audio, effect_type)
        
        # Save processed audio
        output_filename = f"processed_{Path(audio_path).name}"
        output_path = UPLOAD_DIR / output_filename
        
        audio.export(output_path, format="mp3", bitrate="192k")
        
        # Send processed audio
        success_text = f"""
âœ… <b>Audio Ã¼stÃ¼nlikli iÅŸlendi!</b>

ğŸµ <b>GoÅŸulan effektler:</b>
""" + "\n".join([f"â€¢ {EFFECTS[int(eid.split('_')[1])].name}" 
                 for eid in user_sessions[user_id]['effects']]) + """

ğŸ“ <b>FaÃ½l:</b> {output_filename}
â¬‡ï¸ <b>AÅŸakdan faÃ½ly Ã½Ã¼klÃ¤p alyÅˆ:</b>
        """
        
        # Send audio file
        audio_file = FSInputFile(output_path, filename=output_filename)
        await callback.message.answer_audio(
            audio=audio_file,
            caption=success_text,
            title="Processed Audio",
            performer="Audio Effect Bot"
        )
        
        # Clean up
        try:
            Path(audio_path).unlink()
            output_path.unlink()
        except:
            pass
        
        # Reset state
        await state.clear()
        if user_id in user_sessions:
            del user_sessions[user_id]
        
        # Delete processing message
        await processing_msg.delete()
        
    except Exception as e:
        print(f"Error processing audio: {e}")
        await processing_msg.edit_text(f"""
âŒ <b>Audio iÅŸlenilende Ã½alÅˆyÅŸlyk Ã½Ã¼ze Ã§ykdy!</b>

ğŸ”§ <b>SebÃ¤bi:</b> {str(e)}

ğŸ”„ <b>GaÃ½tadan synanyÅŸyÅˆ Ã½a-da admin bilen habarlaÅŸyÅˆ:</b> {ADMIN_USERNAME}
        """)

@router.callback_query(F.data == "clear_selected")
async def clear_selected(callback: CallbackQuery):
    """Clear selected effects"""
    user_id = callback.from_user.id
    
    if user_id in user_sessions:
        user_sessions[user_id]['effects'] = []
        if 'effect_types' in user_sessions[user_id]:
            del user_sessions[user_id]['effect_types']
    
    keyboard = await create_effects_keyboard(user_id)
    await callback.message.edit_reply_markup(reply_markup=keyboard)
    await callback.answer("ğŸ—‘ï¸ SaÃ½lanan effektler arassalandy!")

@router.callback_query(F.data == "back_to_effects")
async def back_to_effects(callback: CallbackQuery):
    """Go back to effects selection"""
    user_id = callback.from_user.id
    
    if user_id not in user_sessions:
        await callback.answer("âŒ Audio faÃ½ly Ã½Ã¼kleÅˆ!", show_alert=True)
        return
    
    keyboard = await create_effects_keyboard(user_id)
    await callback.message.edit_text(
        "ğŸ›ï¸ <b>Effektleri saÃ½laÅˆ:</b>\n\n"
        "AÅŸakdakylardan audioÅˆyza goÅŸmak isleÃ½Ã¤n effektleriÅˆizi saÃ½laÅˆ.",
        reply_markup=keyboard
    )
    await callback.answer()

@router.callback_query(F.data == "back_to_start")
async def back_to_start(callback: CallbackQuery, state: FSMContext):
    """Go back to start menu"""
    await cmd_start(callback.message, state)
    await callback.answer()

@router.callback_query(F.data == "show_effects")
async def show_effects(callback: CallbackQuery):
    """Show all available effects"""
    effects_list = "\n".join([f"â€¢ {effect.name}: {effect.description}" for effect in EFFECTS])
    
    await callback.message.answer(f"""
ğŸ§ <b>ElÃ½eterli Audio Effektler:</b>

{effects_list}

âœ¨ <b>Jemi effektler:</b> {len(EFFECTS)}
ğŸ”§ <b>Her effektiÅˆ gÃ¶rnÃ¼ÅŸi:</b> 3-4 sany

ğŸš€ <b>Audio Ã½Ã¼kle:</b> MP3 faÃ½lyÅˆyzy Ã½Ã¼klemek Ã¼Ã§in /start buÃ½rugyny ulanyÅˆ!
    """)
    await callback.answer()

@router.callback_query(F.data == "about_bot")
async def about_bot(callback: CallbackQuery):
    """Show about bot information"""
    await callback.message.answer(f"""
ğŸ¤– <b>Audio Effect Bot</b>

âœ¨ <b>DÃ¶reden:</b> {ADMIN_USERNAME}
ğŸ“… <b>WersiÃ½a:</b> 1.0.0

ğŸµ <b>Ã–zellikler:</b>
â€¢ 50-e golaÃ½ audio effekt
â€¢ Her effektiÅˆ 3-4 gÃ¶rnÃ¼ÅŸi
â€¢ MP3 formatynda audio iÅŸleme
â€¢ Inline dÃ¼wmeler bilen aÅˆsat ulanylyÅŸ

ğŸ’» <b>TehnologiÃ½alar:</b>
â€¢ Python AIogram 3.x
â€¢ Pydub we MoviePy audio iÅŸleme
â€¢ Telegram Bot API

ğŸ“ <b>KÃ¶mek Ã¼Ã§in:</b> {ADMIN_USERNAME}
    """)
    await callback.answer()

@router.callback_query(F.data == "help")
async def help_command(callback: CallbackQuery):
    """Show help information"""
    await callback.message.answer("""
ğŸ†˜ <b>KÃ¶mek Maslahatlary:</b>

1ï¸âƒ£ <b>Audio Ã½Ã¼klemek:</b>
   â€¢ MP3 formatynda audio faÃ½lyÅˆyzy Ã½Ã¼klÃ¤Åˆ
   â€¢ FaÃ½ly ÅŸu Ã½ere Ã½Ã¼klemegiÅˆizi haÃ½yÅŸ edÃ½Ã¤ris

2ï¸âƒ£ <b>Effekt saÃ½lamak:</b>
   â€¢ GoÅŸmak isleÃ½Ã¤n effektiÅˆizi saÃ½laÅˆ
   â€¢ BirnÃ¤Ã§e effekt saÃ½lap bilersiÅˆiz
   â€¢ Her effektiÅˆ gÃ¶rnÃ¼ÅŸini saÃ½lap bilersiÅˆiz

3ï¸âƒ£ <b>Audio iÅŸlemek:</b>
   â€¢ "Audio-Ã½ iÅŸle" dÃ¼wmesine basyÅˆ
   â€¢ Audio iÅŸleniljek we size iberiljek

4ï¸âƒ£ <b>Problemalar:</b>
   â€¢ FaÃ½l Ã½Ã¼klenilmez bolsa, gaÃ½tadan synanyÅŸyÅˆ
   â€¢ Bot iÅŸlemez bolsa, {ADMIN_USERNAME} bilen habarlaÅŸyÅˆ

ğŸš€ <b>BaÅŸlamak Ã¼Ã§in:</b> /start buÃ½rugyny ulanyÅˆ!
    """)
    await callback.answer()

@router.callback_query(F.data == "no_action")
async def no_action(callback: CallbackQuery):
    """Handle non-action buttons"""
    await callback.answer()

@router.message(Command("admin"))
async def admin_panel(message: Message):
    """Admin panel"""
    if message.from_user.username != ADMIN_USERNAME.replace("@", ""):
        await message.answer("âŒ <b>Bu buÃ½ruk diÅˆe admin Ã¼Ã§in!</b>")
        return
    
    stats_text = f"""
ğŸ‘‘ <b>Admin Paneli</b>

ğŸ“Š <b>Statistikalar:</b>
â€¢ Jemi ulanyjylar: {len(user_sessions)}
â€¢ IÅŸlenÃ½Ã¤n audio faÃ½llar: {len([p for p in UPLOAD_DIR.glob("*") if p.is_file()])}

âš™ï¸ <b>Bot sazlamalary:</b>
â€¢ ElÃ½eterli effektler: {len(EFFECTS)}
â€¢ Her effektiÅˆ gÃ¶rnÃ¼ÅŸi: 3-4 sany

ğŸ› ï¸ <b>Admin buÃ½ruklary:</b>
â€¢ /stats - Bot statistikalary
â€¢ /clean - FaÃ½llary arassala
â€¢ /broadcast - Habar iber
    """
    
    await message.answer(stats_text)

@router.message(Command("stats"))
async def bot_stats(message: Message):
    """Show bot statistics"""
    if message.from_user.username != ADMIN_USERNAME.replace("@", ""):
        await message.answer("âŒ <b>Bu buÃ½ruk diÅˆe admin Ã¼Ã§in!</b>")
        return
    
    stats = f"""
ğŸ“ˆ <b>Bot Statistikalary</b>

ğŸ‘¥ <b>Ulanyjylar:</b>
â€¢ HÃ¤zirki sessiyalar: {len(user_sessions)}
â€¢ FaÃ½l Ã½Ã¼klemeler: {len(list(UPLOAD_DIR.glob("*")))}

ğŸµ <b>Effektler:</b>
â€¢ Jemi effektler: {len(EFFECTS)}
â€¢ Effekt gÃ¶rnÃ¼ÅŸleri: {sum(len(e.types) for e in EFFECTS)}

ğŸ’¾ <b>FaÃ½l ulanylyÅŸy:</b>
â€¢ ÃÃ¼klenen faÃ½llar: UPLOAD_DIR/
â€¢ Effekt faÃ½llary: EFFECTS_DIR/
    """
    
    await message.answer(stats)

# Error handler
@router.errors()
async def error_handler(event, **kwargs):
    """Handle errors"""
    print(f"Error occurred: {event.exception}")
    return True

# Main function
async def main():
    """Main function"""
    print("ğŸ¤– Audio Effect Bot iÅŸe baÅŸlady...")
    print(f"ğŸ‘‘ Admin: {ADMIN_USERNAME}")
    print("ğŸš€ Bot hazyr! /start buÃ½rugy bilen baÅŸlap bilersiÅˆiz...")
    
    await dp.start_polling(bot)

if __name__ == "__main__":
    # Check audio support
    if not AUDIO_SUPPORT:
        print("âš ï¸  Audio processing libraries not installed!")
        print("ğŸ“¦ Install with: pip install pydub moviepy numpy")
    
    # Run bot
    asyncio.run(main())
